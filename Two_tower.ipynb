{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load data\n",
    "# movies_df = pd.read_csv('/home1/chenpaul/EE557/MovieLens/movie.csv')\n",
    "ratings_df = pd.read_csv('/home1/chenpaul/EE557/MovieLens/rating.csv')\n",
    "# genome_scores_df = pd.read_csv('/home1/chenpaul/EE557/MovieLens/genome_scores.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000258</th>\n",
       "      <td>138493</td>\n",
       "      <td>68954</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-11-13 15:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000259</th>\n",
       "      <td>138493</td>\n",
       "      <td>69526</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-12-03 18:31:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000260</th>\n",
       "      <td>138493</td>\n",
       "      <td>69644</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2009-12-07 18:10:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000261</th>\n",
       "      <td>138493</td>\n",
       "      <td>70286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2009-11-13 15:42:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000262</th>\n",
       "      <td>138493</td>\n",
       "      <td>71619</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2009-10-17 20:25:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000263 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating            timestamp\n",
       "0              1        2     3.5  2005-04-02 23:53:47\n",
       "1              1       29     3.5  2005-04-02 23:31:16\n",
       "2              1       32     3.5  2005-04-02 23:33:39\n",
       "3              1       47     3.5  2005-04-02 23:32:07\n",
       "4              1       50     3.5  2005-04-02 23:29:40\n",
       "...          ...      ...     ...                  ...\n",
       "20000258  138493    68954     4.5  2009-11-13 15:42:00\n",
       "20000259  138493    69526     4.5  2009-12-03 18:31:48\n",
       "20000260  138493    69644     3.0  2009-12-07 18:10:57\n",
       "20000261  138493    70286     5.0  2009-11-13 15:42:24\n",
       "20000262  138493    71619     2.5  2009-10-17 20:25:36\n",
       "\n",
       "[20000263 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset class\n",
    "class MovieLensDataset(Dataset):\n",
    "    # def __init__(self, ratings_df, user_features_df, movie_features_df):\n",
    "    #     self.user_features = torch.tensor(user_features_df.loc[ratings_df['userId']].values, dtype=torch.float32)\n",
    "    #     self.movie_features = torch.tensor(movie_features_df.loc[ratings_df['movieId']].values, dtype=torch.float32)\n",
    "    #     self.ratings = torch.tensor(ratings_df['rating'].values, dtype=torch.float32)\n",
    "\n",
    "    # def __len__(self):\n",
    "    #     return len(self.ratings)\n",
    "\n",
    "    # def __getitem__(self, idx):\n",
    "    #     return self.user_features[idx], self.movie_features[idx], self.ratings[idx]\n",
    "    def __init__(self, df:pd.DataFrame, user_features, item_features, label):\n",
    "        self.user_id = df[user_features].values\n",
    "        self.movie_id = df[item_features].values\n",
    "        self.rating = df[label].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_id)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        user_id = self.user_id[idx]\n",
    "        movie_id = self.movie_id[idx]\n",
    "        rating = self.rating[idx]\n",
    "\n",
    "        return [torch.tensor(user_id), torch.tensor(movie_id)], torch.tensor(rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of unique userIds and movieIds to keep\n",
    "max_user_id = 10000  # for example, top 1000 users\n",
    "max_movie_id = 5000  # for example, top 500 movies\n",
    "\n",
    "# Get the top userIds and movieIds\n",
    "filtered_df = ratings_df[(ratings_df['userId'] < max_user_id) & (ratings_df['movieId'] < max_movie_id)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# rating_matrix = ratings_df.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "# rating_matrix = csr_matrix((ratings_df['rating'], (ratings_df['userId'], ratings_df['movieId'])))\n",
    "# Load movie titles\n",
    "df_title = pd.read_csv('/home1/chenpaul/EE557/MovieLens/movie.csv')#, encoding=\"ISO-8859-1\", header=None, names=['movieId', 'Year', 'Name'], on_bad_lines='skip')\n",
    "df_title.set_index('movieId', inplace=True)\n",
    "\n",
    "# Merge ratings with movie titles\n",
    "df_title.index = df_title.index.astype('int')\n",
    "df_two_tower = filtered_df.merge(df_title, left_on='movieId', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998\n",
      "4835\n"
     ]
    }
   ],
   "source": [
    "print(df_two_tower['userId'].nunique())\n",
    "print(df_two_tower['movieId'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = [\"userId\"]\n",
    "item_features = [\"movieId\"]\n",
    "label = [\"rating\"]\n",
    "train_data, test_data = train_test_split(df_two_tower, test_size=0.2)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(MovieLensDataset(\n",
    "        train_data,\n",
    "        user_features,\n",
    "        item_features,\n",
    "        label), batch_size=64, shuffle=False)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(MovieLensDataset(\n",
    "      test_data,\n",
    "      user_features,\n",
    "      item_features,\n",
    "      label), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110658</th>\n",
       "      <td>761</td>\n",
       "      <td>267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1998-08-15 01:29:33</td>\n",
       "      <td>Major Payne (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130568</th>\n",
       "      <td>892</td>\n",
       "      <td>1545</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2001-01-02 21:21:23</td>\n",
       "      <td>Ponette (1996)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752723</th>\n",
       "      <td>5015</td>\n",
       "      <td>3593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2008-10-28 23:18:57</td>\n",
       "      <td>Battlefield Earth (2000)</td>\n",
       "      <td>Action|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780022</th>\n",
       "      <td>5192</td>\n",
       "      <td>3082</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-01-31 14:10:49</td>\n",
       "      <td>World Is Not Enough, The (1999)</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44334</th>\n",
       "      <td>343</td>\n",
       "      <td>2797</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2004-06-27 16:08:38</td>\n",
       "      <td>Big (1988)</td>\n",
       "      <td>Comedy|Drama|Fantasy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691218</th>\n",
       "      <td>4587</td>\n",
       "      <td>434</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2006-01-28 10:19:44</td>\n",
       "      <td>Cliffhanger (1993)</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385870</th>\n",
       "      <td>9403</td>\n",
       "      <td>3100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2000-01-17 03:40:56</td>\n",
       "      <td>River Runs Through It, A (1992)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429202</th>\n",
       "      <td>9653</td>\n",
       "      <td>356</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999-09-18 10:18:39</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "      <td>Comedy|Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458699</th>\n",
       "      <td>3138</td>\n",
       "      <td>1221</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1997-05-26 08:17:00</td>\n",
       "      <td>Godfather: Part II, The (1974)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218678</th>\n",
       "      <td>8351</td>\n",
       "      <td>1307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-12-13 04:41:59</td>\n",
       "      <td>When Harry Met Sally... (1989)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>913523 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId  rating            timestamp  \\\n",
       "110658      761      267     1.0  1998-08-15 01:29:33   \n",
       "130568      892     1545     3.0  2001-01-02 21:21:23   \n",
       "752723     5015     3593     1.0  2008-10-28 23:18:57   \n",
       "780022     5192     3082     4.0  2015-01-31 14:10:49   \n",
       "44334       343     2797     4.0  2004-06-27 16:08:38   \n",
       "...         ...      ...     ...                  ...   \n",
       "691218     4587      434     1.5  2006-01-28 10:19:44   \n",
       "1385870    9403     3100     3.0  2000-01-17 03:40:56   \n",
       "1429202    9653      356     3.0  1999-09-18 10:18:39   \n",
       "458699     3138     1221     4.0  1997-05-26 08:17:00   \n",
       "1218678    8351     1307     5.0  1999-12-13 04:41:59   \n",
       "\n",
       "                                   title                        genres  \n",
       "110658                Major Payne (1995)                        Comedy  \n",
       "130568                    Ponette (1996)                         Drama  \n",
       "752723          Battlefield Earth (2000)                 Action|Sci-Fi  \n",
       "780022   World Is Not Enough, The (1999)     Action|Adventure|Thriller  \n",
       "44334                         Big (1988)  Comedy|Drama|Fantasy|Romance  \n",
       "...                                  ...                           ...  \n",
       "691218                Cliffhanger (1993)     Action|Adventure|Thriller  \n",
       "1385870  River Runs Through It, A (1992)                         Drama  \n",
       "1429202              Forrest Gump (1994)      Comedy|Drama|Romance|War  \n",
       "458699    Godfather: Part II, The (1974)                   Crime|Drama  \n",
       "1218678   When Harry Met Sally... (1989)                Comedy|Romance  \n",
       "\n",
       "[913523 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, user_embedding_num, user_embedding_dim, item_embedding_num, item_embedding_dim):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(user_embedding_num, user_embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(item_embedding_num, item_embedding_dim)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # User Tower\n",
    "        self.user_tower = nn.Sequential(\n",
    "            nn.Linear(user_embedding_dim, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Item Tower\n",
    "        self.item_tower = nn.Sequential(\n",
    "            nn.Linear(item_embedding_dim, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        user_embed = self.flatten(self.user_embedding(X[0]))\n",
    "        item_embed = self.flatten(self.item_embedding(X[1]))\n",
    "\n",
    "        user = self.user_tower(user_embed)\n",
    "        item = self.item_tower(item_embed)\n",
    "        score = torch.mul(user, item).sum(1)\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoTowerModel(max_user_id+1, 300, max_movie_id+1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TwoTowerModel(\n",
       "  (user_embedding): Embedding(10001, 300)\n",
       "  (item_embedding): Embedding(5001, 300)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (user_tower): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (item_tower): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # Using Mean Squared Error Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "913523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/chenpaul/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 11.769237  [    2/913523]\n",
      "loss: 1.438290  [ 2002/913523]\n",
      "loss: 1.186611  [ 4002/913523]\n",
      "loss: 1.271615  [ 6002/913523]\n",
      "loss: 0.858905  [ 8002/913523]\n",
      "loss: 1.358911  [10002/913523]\n",
      "loss: 0.769211  [12002/913523]\n",
      "loss: 1.047344  [14002/913523]\n",
      "loss: 1.288637  [16002/913523]\n",
      "loss: 1.472014  [18002/913523]\n",
      "loss: 0.929650  [20002/913523]\n",
      "loss: 1.011623  [22002/913523]\n",
      "loss: 1.138462  [24002/913523]\n",
      "loss: 0.951426  [26002/913523]\n",
      "loss: 1.349313  [28002/913523]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/chenpaul/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([51, 1])) that is different to the input size (torch.Size([51])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home1/chenpaul/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([29, 1])) that is different to the input size (torch.Size([29])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " , Avg loss: 1.134348 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "913523\n",
      "loss: 1.605229  [    2/913523]\n",
      "loss: 1.356050  [ 2002/913523]\n",
      "loss: 1.135738  [ 4002/913523]\n",
      "loss: 1.250906  [ 6002/913523]\n",
      "loss: 0.826204  [ 8002/913523]\n",
      "loss: 1.316488  [10002/913523]\n",
      "loss: 0.749931  [12002/913523]\n",
      "loss: 0.993272  [14002/913523]\n",
      "loss: 1.293151  [16002/913523]\n",
      "loss: 1.501116  [18002/913523]\n",
      "loss: 0.927680  [20002/913523]\n",
      "loss: 1.064257  [22002/913523]\n",
      "loss: 1.119059  [24002/913523]\n",
      "loss: 0.975105  [26002/913523]\n",
      "loss: 1.339210  [28002/913523]\n",
      "Test Error: \n",
      " , Avg loss: 1.128046 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "913523\n",
      "loss: 1.567344  [    2/913523]\n",
      "loss: 1.355565  [ 2002/913523]\n",
      "loss: 1.138258  [ 4002/913523]\n",
      "loss: 1.247387  [ 6002/913523]\n",
      "loss: 0.819436  [ 8002/913523]\n",
      "loss: 1.316662  [10002/913523]\n",
      "loss: 0.750191  [12002/913523]\n",
      "loss: 0.993463  [14002/913523]\n",
      "loss: 1.292635  [16002/913523]\n",
      "loss: 1.501451  [18002/913523]\n",
      "loss: 0.928525  [20002/913523]\n",
      "loss: 1.057030  [22002/913523]\n",
      "loss: 1.120158  [24002/913523]\n",
      "loss: 0.975082  [26002/913523]\n",
      "loss: 1.338452  [28002/913523]\n",
      "Test Error: \n",
      " , Avg loss: 1.127676 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "913523\n",
      "loss: 1.569060  [    2/913523]\n",
      "loss: 1.354731  [ 2002/913523]\n",
      "loss: 1.138538  [ 4002/913523]\n",
      "loss: 1.247522  [ 6002/913523]\n",
      "loss: 0.819510  [ 8002/913523]\n",
      "loss: 1.316604  [10002/913523]\n",
      "loss: 0.750250  [12002/913523]\n",
      "loss: 0.993141  [14002/913523]\n",
      "loss: 1.292647  [16002/913523]\n",
      "loss: 1.501735  [18002/913523]\n",
      "loss: 0.928170  [20002/913523]\n",
      "loss: 1.056957  [22002/913523]\n",
      "loss: 1.120189  [24002/913523]\n",
      "loss: 0.975002  [26002/913523]\n",
      "loss: 1.338472  [28002/913523]\n",
      "Test Error: \n",
      " , Avg loss: 1.127481 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "913523\n",
      "loss: 1.567534  [    2/913523]\n",
      "loss: 1.354671  [ 2002/913523]\n",
      "loss: 1.138740  [ 4002/913523]\n",
      "loss: 1.247407  [ 6002/913523]\n",
      "loss: 0.819571  [ 8002/913523]\n",
      "loss: 1.317646  [10002/913523]\n",
      "loss: 0.750193  [12002/913523]\n",
      "loss: 0.993137  [14002/913523]\n",
      "loss: 1.292696  [16002/913523]\n",
      "loss: 1.501951  [18002/913523]\n",
      "loss: 0.928413  [20002/913523]\n",
      "loss: 1.056302  [22002/913523]\n",
      "loss: 1.120132  [24002/913523]\n",
      "loss: 0.974936  [26002/913523]\n",
      "loss: 1.338440  [28002/913523]\n",
      "Test Error: \n",
      " , Avg loss: 1.127395 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    print(size)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = (X[0].to(device).long(), X[1].to(device).long()), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.float())\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = (X[0].to(device).long(), X[1].to(device).long()), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y.float()).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n , Avg loss: {test_loss:>8f} \\n\")\n",
    "def fit(model, loss_fn, optimizer, train_dataloader, test_dataloader, epochs=5):\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test(test_dataloader, model, loss_fn)\n",
    "    print(\"Done!\")\n",
    "fit(model, criterion, optimizer, train_dataloader, test_dataloader,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
